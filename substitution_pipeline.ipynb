{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM+7XwVeu3p0oB6HUhlgzo6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vihan-lakshman/mutagenic/blob/main/substitution_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "SaEBvUPBhyp2"
      },
      "outputs": [],
      "source": [
        "# prompt: read in '/content/prelim-deletion-validation-dataset-functional-annotations.csv'\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "df = pd.read_csv('/content/subset_nonfunctional_DMS_substitutions_with_interpro.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "awTZby72rrAP",
        "outputId": "cce9ce80-b5f1-47f5-c632-49e45470f2c3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        mutant                                   mutated_sequence  DMS_score  \\\n",
              "0         L43P  SPEVQIAILTEQINNLNEHLRVHKKDHHSRRGLLKMVGKRRRPLAY...  -3.196763   \n",
              "1         L56N  EAHAAIDTFTKYLDIDEDFATVLVEEGFSTLEELAYVPMKELLEIE...  -3.952602   \n",
              "2        I182K  MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...  -0.045873   \n",
              "3          Q2E  MEFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKV...  -9.000000   \n",
              "4  G324V:G344M  MDCLCIVTTKKYRYQDEDTPPLEHSPAHLPNQANSPPVIVNTDTLE...  -1.545841   \n",
              "\n",
              "                                        wildtype_seq   UniProt_ID  \\\n",
              "0  SPEVQIAILTEQINNLNEHLRVHKKDHHSRRGLLKMVGKRRRLLAY...   RS15_GEOSE   \n",
              "1  EAHAAIDTFTKYLDIDEDFATVLVEEGFSTLEELAYVPMKELLEIE...   NUSA_ECOLI   \n",
              "2  MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...  CP2C9_HUMAN   \n",
              "3  MQFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKV...   CCDB_ECOLI   \n",
              "4  MDCLCIVTTKKYRYQDEDTPPLEHSPAHLPNQANSPPVIVNTDTLE...   DLG4_HUMAN   \n",
              "\n",
              "                                            InterPro  \n",
              "0                     IPR000589;IPR005290;IPR009068;  \n",
              "1  IPR010995;IPR015946;IPR025249;IPR009019;IPR012...  \n",
              "2  IPR001128;IPR017972;IPR002401;IPR036396;IPR050...  \n",
              "3                               IPR002712;IPR011067;  \n",
              "4  IPR019583;IPR016313;IPR019590;IPR008145;IPR008...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7227f518-2dc9-4126-8772-fd32d5a32f59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mutant</th>\n",
              "      <th>mutated_sequence</th>\n",
              "      <th>DMS_score</th>\n",
              "      <th>wildtype_seq</th>\n",
              "      <th>UniProt_ID</th>\n",
              "      <th>InterPro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L43P</td>\n",
              "      <td>SPEVQIAILTEQINNLNEHLRVHKKDHHSRRGLLKMVGKRRRPLAY...</td>\n",
              "      <td>-3.196763</td>\n",
              "      <td>SPEVQIAILTEQINNLNEHLRVHKKDHHSRRGLLKMVGKRRRLLAY...</td>\n",
              "      <td>RS15_GEOSE</td>\n",
              "      <td>IPR000589;IPR005290;IPR009068;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L56N</td>\n",
              "      <td>EAHAAIDTFTKYLDIDEDFATVLVEEGFSTLEELAYVPMKELLEIE...</td>\n",
              "      <td>-3.952602</td>\n",
              "      <td>EAHAAIDTFTKYLDIDEDFATVLVEEGFSTLEELAYVPMKELLEIE...</td>\n",
              "      <td>NUSA_ECOLI</td>\n",
              "      <td>IPR010995;IPR015946;IPR025249;IPR009019;IPR012...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I182K</td>\n",
              "      <td>MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...</td>\n",
              "      <td>-0.045873</td>\n",
              "      <td>MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...</td>\n",
              "      <td>CP2C9_HUMAN</td>\n",
              "      <td>IPR001128;IPR017972;IPR002401;IPR036396;IPR050...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q2E</td>\n",
              "      <td>MEFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKV...</td>\n",
              "      <td>-9.000000</td>\n",
              "      <td>MQFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKV...</td>\n",
              "      <td>CCDB_ECOLI</td>\n",
              "      <td>IPR002712;IPR011067;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>G324V:G344M</td>\n",
              "      <td>MDCLCIVTTKKYRYQDEDTPPLEHSPAHLPNQANSPPVIVNTDTLE...</td>\n",
              "      <td>-1.545841</td>\n",
              "      <td>MDCLCIVTTKKYRYQDEDTPPLEHSPAHLPNQANSPPVIVNTDTLE...</td>\n",
              "      <td>DLG4_HUMAN</td>\n",
              "      <td>IPR019583;IPR016313;IPR019590;IPR008145;IPR008...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7227f518-2dc9-4126-8772-fd32d5a32f59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7227f518-2dc9-4126-8772-fd32d5a32f59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7227f518-2dc9-4126-8772-fd32d5a32f59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8bb03e47-1831-4516-80f8-5d9d3bb617cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bb03e47-1831-4516-80f8-5d9d3bb617cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8bb03e47-1831-4516-80f8-5d9d3bb617cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 217,\n  \"fields\": [\n    {\n      \"column\": \"mutant\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 217,\n        \"samples\": [\n          \"L26N\",\n          \"K16D:E26T\",\n          \"H114K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mutated_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 217,\n        \"samples\": [\n          \"TLDMDAVLSDFVRSTGAEPGLARDLNEGKNWDLTAALSDYEQ\",\n          \"MISNAKIARINELAADAKAGVITEETKAEQQKLRQEYLK\",\n          \"MFKLLSKLLVYLTASIMAIASPLAFSVDSSGEYPTVSEIPVGEVRLYQIADGVWSHIATQSFDGAVYPSNGLIVRDGDELLLIDTAWGAKNTAALLAEIEKQIGLPVTRAVSTKFHDDRVGGVDVLRAAGVATYASPSTRRLAEVEGNEIPTHSLEGLSSSGDAVRFGPVELFYPGAAHSTDNLIVYVPSASVLYGGCAIYELSRTSAGNVADADLAEWPTSIERIQQHYPEAQFVIPGHGLPGGLDLLKHTTNVVKAHTNRSVVE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DMS_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 179266.0312479704,\n        \"min\": -205.5,\n        \"max\": 2640756.73,\n        \"num_unique_values\": 208,\n        \"samples\": [\n          -2.198392622,\n          -5.321928,\n          -1.870851279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wildtype_seq\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 186,\n        \"samples\": [\n          \"MKFVKRRIIALVTILMLSVTSLFALQPSAKAAEHNPVVMVHGIGGASFNFAGIKSYLVSQGWSRDKLYAVDFWDKTGTNYNNGPVLSRFVQKVLDETGAKKVDIVAHSMGGANTLYYIKNLDGGNKVANVVTLGGANRLTTGKALPGTDPNQKILYTSIYSSADMIVMNYLSRLDGARNVQIHGVGHIGLLYSSQVNSLIKEGLNGGGQNTN\",\n          \"KLPPGWEKRMSRSSGRVYYFNHITNASQWERPSGNSSSG\",\n          \"MGQPGNGSAFLLAPNGSHAPDHDVTQERDEVWVVGMGIVMSLIVLAIVFGNVLVITAIAKFERLQTVTNYFITSLACADLVMGLAVVPFGAAHILMKMWTFGNFWCEFWTSIDVLCVTASIETLCVIAVDRYFAITSPFKYQSLLTKNKARVIILMVWIVSGLTSFLPIQMHWYRATHQEAINCYANETCCDFFTNQAYAIASSIVSFYVPLVIMVFVYSRVFQEAKRQLQKIDKSEGRFHVQNLSQVEQDGRTGHGLRRSSKFCLKEHKALKTLGIIMGTFTLCWLPFFIVNIVHVIQDNLIRKEVYILLNWIGYVNSGFNPLIYCRSPDFRIAFQELLCLRRSSLKAYGNGYSSNGNTGEQSGYHVEQEKENKLLCEDLPGTEDFVGHQGTVPSDNIDSQGRNCSTNDSLL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UniProt_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 185,\n        \"samples\": [\n          \"SDA_BACSU\",\n          \"RNC_ECOLI\",\n          \"MBD11_ARATH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"InterPro\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 169,\n        \"samples\": [\n          \"IPR004806;IPR041811;IPR006636;IPR015940;IPR009060;IPR000626;IPR029071;IPR015360;IPR036353;\",\n          \"IPR050113;IPR000608;IPR023313;IPR016135;\",\n          \"IPR005338;IPR043129;\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-RwxePzFrrFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install blosum\n",
        "import blosum as bl\n",
        "matrix = bl.BLOSUM(80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUATqv6QiR86",
        "outputId": "3511e13d-60d1-4d77-8498-1e76057664b2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: blosum in /usr/local/lib/python3.10/dist-packages (2.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: for each row, identify the substring that starts at del_start (counting from 1, not 0), and ends at del_end, and for each letter in that substring, it is a amino acid residue that should be randomly replaced with one of the 20 amino acids. save this as \"substituted_seq\" in a column after \"truncated_seq\"\n",
        "\n",
        "import random\n",
        "\n",
        "# List of standard amino acid single-letter codes\n",
        "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "\n",
        "def substitute_substring(sequence, del_start, del_end):\n",
        "    \"\"\"Substitutes amino acids in a substring with random amino acids.\"\"\"\n",
        "\n",
        "    # Adjust del_start to be 0-indexed\n",
        "    #del_start -= 1\n",
        "\n",
        "    if del_start < 0 or del_end > len(sequence) or del_start >= del_end:\n",
        "        return sequence  # Handle invalid indices\n",
        "\n",
        "    substituted_seq = list(sequence)\n",
        "    for i in range(del_start, del_end):\n",
        "        substituted_seq[i] = random.choice(amino_acids)\n",
        "\n",
        "    return \"\".join(substituted_seq)\n",
        "\n",
        "\n",
        "#Apply the function to each row of the DataFrame\n",
        "df['substituted_seq'] = df['mutated_sequence']\n",
        "df['substituted_seq'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "zVyLOSEdirvP",
        "outputId": "5805bb18-89b6-4b7c-929a-4feeb497b364"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    SPEVQIAILTEQINNLNEHLRVHKKDHHSRRGLLKMVGKRRRPLAY...\n",
              "1    EAHAAIDTFTKYLDIDEDFATVLVEEGFSTLEELAYVPMKELLEIE...\n",
              "2    MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...\n",
              "3    MEFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKV...\n",
              "4    MDCLCIVTTKKYRYQDEDTPPLEHSPAHLPNQANSPPVIVNTDTLE...\n",
              "Name: substituted_seq, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>substituted_seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SPEVQIAILTEQINNLNEHLRVHKKDHHSRRGLLKMVGKRRRPLAY...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EAHAAIDTFTKYLDIDEDFATVLVEEGFSTLEELAYVPMKELLEIE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MEFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MDCLCIVTTKKYRYQDEDTPPLEHSPAHLPNQANSPPVIVNTDTLE...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to hold the results\n",
        "embeddings_dict = {}\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for _, row in df.iterrows():\n",
        "    entry = row['UniProt_ID']\n",
        "    interpro = row['InterPro']\n",
        "\n",
        "    # Skip rows where 'Interpro' is None\n",
        "    if pd.isna(interpro) or not interpro.strip():\n",
        "        continue\n",
        "\n",
        "    # Split the InterPro IDs by semicolons\n",
        "    interpro_ids = interpro.split(';')\n",
        "    interpro_ids = interpro_ids[:-1]\n",
        "\n",
        "    # Initialize entry in the dictionary if not present\n",
        "    if entry not in embeddings_dict:\n",
        "        embeddings_dict[entry] = {\n",
        "            'InterPro_ids': interpro_ids\n",
        "        }"
      ],
      "metadata": {
        "id": "XL-f4AFrns1e"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install esm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VROBmFu2nu2m",
        "outputId": "e0892da4-d4f8-403c-9791-5f3663aa8e23"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: esm in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from esm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from esm) (0.20.1+cu121)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (from esm) (0.18.0)\n",
            "Requirement already satisfied: transformers<4.47.0 in /usr/local/lib/python3.10/dist-packages (from esm) (4.46.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from esm) (7.34.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from esm) (0.8.0)\n",
            "Requirement already satisfied: biotite==0.41.2 in /usr/local/lib/python3.10/dist-packages (from esm) (0.41.2)\n",
            "Requirement already satisfied: msgpack-numpy in /usr/local/lib/python3.10/dist-packages (from esm) (0.4.8)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (from esm) (1.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from esm) (1.5.2)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from esm) (1.1.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from esm) (24.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from esm) (2.2.2)\n",
            "Requirement already satisfied: cloudpathlib in /usr/local/lib/python3.10/dist-packages (from esm) (0.20.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from esm) (9.0.0)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from biotite==0.41.2->esm) (1.1.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from biotite==0.41.2->esm) (3.4.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from biotite==0.41.2->esm) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.12 in /usr/local/lib/python3.10/dist-packages (from biotite==0.41.2->esm) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->esm) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->esm) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->esm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->esm) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->esm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.2.0->esm) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<4.47.0->esm) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<4.47.0->esm) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.47.0->esm) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.47.0->esm) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<4.47.0->esm) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.47.0->esm) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<4.47.0->esm) (4.66.6)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->esm) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->esm) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->esm) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->esm) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->esm) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->esm) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->esm) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->esm) (11.0.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->esm) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->esm) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->esm) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->esm) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite==0.41.2->esm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite==0.41.2->esm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite==0.41.2->esm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite==0.41.2->esm) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0->esm) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from esm.models.esm3 import ESM3\n",
        "from esm.sdk.api import ESM3InferenceClient, ESMProtein, GenerationConfig\n",
        "\n",
        "# Will instruct you how to get an API key from huggingface hub, make one with \"Read\" permission.\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "eNwBA8Ernw8e"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model: ESM3InferenceClient = ESM3.from_pretrained(\"esm3_sm_open_v1\").to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mNkJiyEn449",
        "outputId": "6915030b-7fd1-404c-ec52-8c92f580cb33"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/esm/pretrained.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from esm.tokenization import InterProQuantizedTokenizer\n",
        "from esm.utils.types import FunctionAnnotation\n",
        "\n",
        "def get_keywords_from_interpro(\n",
        "    interpro_annotations,\n",
        "    interpro2keywords=InterProQuantizedTokenizer().interpro2keywords,\n",
        "):\n",
        "    keyword_annotations_list = []\n",
        "    for interpro_annotation in interpro_annotations:\n",
        "        keywords = interpro2keywords.get(interpro_annotation.label, [])\n",
        "        keyword_annotations_list.extend([\n",
        "            FunctionAnnotation(\n",
        "                label=keyword,\n",
        "                start=interpro_annotation.start,\n",
        "                end=interpro_annotation.end,\n",
        "            )\n",
        "            for keyword in keywords\n",
        "        ])\n",
        "    return keyword_annotations_list"
      ],
      "metadata": {
        "id": "4iDJPAahn5Ag"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#protein that only has one function?\n",
        "#longer sequences of all As, all Gs, or completely random\n",
        "def get_label_embedding(interpro_label,sequence):\n",
        "  hostProtein = ESMProtein(sequence=sequence)\n",
        "  embedding_function = model.encoder.function_embed\n",
        "  hostProtein.function_annotations = get_keywords_from_interpro([FunctionAnnotation(label=interpro_label, start=1, end=len(sequence))])\n",
        "  hostProtein_tensor = model.encode(hostProtein)\n",
        "  device = hostProtein_tensor.function.device  # Get the device of protein2_tensor.function\n",
        "  embedding_function = embedding_function.to(device)  # Move embedding_function to the device\n",
        "\n",
        "  function_embed = torch.cat(\n",
        "      [\n",
        "          embed_fn(funcs.to(device)) # Ensure funcs is on the same device\n",
        "          for embed_fn, funcs in zip(\n",
        "              embedding_function, hostProtein_tensor.function.unbind(-1)\n",
        "          )\n",
        "      ],\n",
        "      -1,\n",
        "  )\n",
        "  if function_embed.shape[0] >= 3:\n",
        "      row_sum = function_embed.sum(dim=0)  # Sum all rows\n",
        "      row_avg = row_sum / (function_embed.shape[0] - 2)  # Divide by (number of rows - 2)\n",
        "      row_avg_np = row_avg.cpu().detach().type(torch.float32).numpy()\n",
        "      return row_avg_np\n",
        "  else:\n",
        "      return None"
      ],
      "metadata": {
        "id": "mEQYblSAoQ6h"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "for entry, interpro_ids in embeddings_dict.items():\n",
        "  embeddings = []\n",
        "  for interpro_id in interpro_ids['InterPro_ids']:\n",
        "    # embeddings.append(get_label_embedding(interpro_id,\"A\"))\n",
        "    label_embedding = get_label_embedding(interpro_id,\"A\")\n",
        "    embeddings.append(label_embedding)\n",
        "\n",
        "  #embeddings = torch.stack(embeddings, dim=0)\n",
        "  #avg_embedding = torch.mean(embeddings)\n",
        "  embeddings_dict[entry]['embedding'] = embeddings"
      ],
      "metadata": {
        "id": "dkmGE309oTcj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_masking_model(\n",
        "    prompt,\n",
        "    model,\n",
        "    df,\n",
        "    embeddings_dict,\n",
        "    percentage=10,\n",
        "):\n",
        "    \"\"\"\n",
        "    Helper function to process a protein sequence, calculate similarities,\n",
        "    and return indices for masking.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The protein sequence to be processed.\n",
        "        model: The model used for protein generation and embeddings.\n",
        "        df (pd.DataFrame): DataFrame containing protein data.\n",
        "        embeddings_dict (dict): Dictionary storing embeddings and other details.\n",
        "\n",
        "    Returns:\n",
        "        List[int]: Indices used for masking in the sequence.\n",
        "    \"\"\"\n",
        "    # Create an ESMProtein object\n",
        "    protein = ESMProtein(sequence=prompt)\n",
        "\n",
        "    # Configure the model for generation\n",
        "    generation_config = GenerationConfig(track=\"function\", num_steps=8)\n",
        "\n",
        "    # Generate the protein\n",
        "    generated_protein = model.generate(protein, generation_config)\n",
        "\n",
        "    # Check if function annotations are available\n",
        "    entry = df.loc[df['substituted_seq'] == prompt, 'UniProt_ID'].iloc[0]\n",
        "    if generated_protein.function_annotations is None:\n",
        "        embeddings_dict[entry]['hamming_distance'] = None\n",
        "        return []\n",
        "\n",
        "    # Getting embedding for the protein\n",
        "    protein_tensor = model.encode(generated_protein)\n",
        "    embedding_function = model.encoder.function_embed\n",
        "    device = protein_tensor.function.device  # Get the device of protein_tensor.function\n",
        "    embedding_function = embedding_function.to(device)  # Move embedding_function to the device\n",
        "\n",
        "    function_embed = torch.cat(\n",
        "        [\n",
        "            embed_fn(funcs.to(device))  # Ensure funcs is on the same device\n",
        "            for embed_fn, funcs in zip(\n",
        "                embedding_function, protein_tensor.function.unbind(-1)\n",
        "            )\n",
        "        ],\n",
        "        -1,\n",
        "    )\n",
        "\n",
        "    # Exclude start and end tokens\n",
        "    function_embed = function_embed[1:-1, :]\n",
        "\n",
        "    # Convert the protein_tensor.function to a NumPy array\n",
        "    protein_np = function_embed.cpu().detach().type(torch.float32).numpy()\n",
        "    print(protein_np.shape)\n",
        "    return None\n",
        "\n",
        "    # Retrieve target sequence and embedding\n",
        "    embedding = embeddings_dict[entry]['embedding']\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    embedding = embedding.cpu().detach().type(torch.float32).numpy()\n",
        "    similarities = cosine_similarity(protein_np, embedding.reshape(1, -1))\n",
        "\n",
        "    num_indices = int(len(prompt) * percentage / 100)\n",
        "\n",
        "    # Ensure we select at least 1 index\n",
        "    num_indices = max(1, num_indices)\n",
        "\n",
        "    # Find the top 10 indices with the lowest cosine similarity\n",
        "    indices = np.argsort(similarities.flatten())[:num_indices]\n",
        "\n",
        "    # Store the indices in the embeddings_dict\n",
        "    embeddings_dict[entry]['indices'] = indices.tolist()\n",
        "\n",
        "    return indices.tolist()"
      ],
      "metadata": {
        "id": "OVe699BHoWlW"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculatedist(proteinembed,targetembed):\n",
        "  alldist = []\n",
        "  for embedding in proteinembed:\n",
        "    dist = cosine_similarity(embedding, targetembed.reshape(1, -1))\n",
        "    alldist.append(dist**2)\n",
        "  return alldist"
      ],
      "metadata": {
        "id": "cfjqZCUlodyL"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "row = df.iloc[0]\n",
        "maskedindeces = embedding_masking_model(row['substituted_seq'], model, df, embeddings_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CGJQ8qnod0f",
        "outputId": "9c03752f-fce6-4431-d136-c087493eff20"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 12.29it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/esm/pretrained.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\n",
            "/usr/local/lib/python3.10/dist-packages/esm/pretrained.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(63, 1536)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_indices(prompt, percentage):\n",
        "    \"\"\"\n",
        "    Randomly select indices to mask based on the percentage of the prompt's length.\n",
        "    \"\"\"\n",
        "    num_indices = int(len(prompt) * percentage / 100)\n",
        "    # Ensure we select at least one index\n",
        "    num_indices = max(1, num_indices)\n",
        "\n",
        "    # Randomly select unique indices to mask\n",
        "    return random.sample(range(len(prompt)), num_indices)"
      ],
      "metadata": {
        "id": "i1UU1pcmod20"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RICHIE RUN THIS!!!!!\n",
        "\n",
        "import math\n",
        "allnuminterpro = []\n",
        "# allpercentmasks = df['percent_deleted'].tolist()\n",
        "allpercentidentities = []\n",
        "allindexes = []\n",
        "allmasked = []\n",
        "sequence_similarity = []\n",
        "masked_sequence = []\n",
        "generated_sequence_list = []\n",
        "for index, row in df.iterrows():\n",
        "  if row[\"UniProt_ID\"] not in embeddings_dict:\n",
        "    continue\n",
        "  try:\n",
        "    maskedindeces = embedding_masking_model(row['substituted_seq'], model, df, embeddings_dict,)\n",
        "  except:\n",
        "    torch.cuda.empty_cache()\n",
        "    continue\n",
        "  if not maskedindeces:\n",
        "    continue\n",
        "  allindexes.append(index)\n",
        "  numinterpro = int(len(row['InterPro'])/10)\n",
        "  allnuminterpro.append(numinterpro)\n",
        "  correctmasks = set(np.arange(row['del_start'],row['del_end']+1))\n",
        "  truncatedpredictions = set(maskedindeces[:len(correctmasks)])\n",
        "  allmasked.append(truncatedpredictions)\n",
        "  identical_count = len(truncatedpredictions.intersection(correctmasks))\n",
        "  percent_identity = (identical_count / len(correctmasks))\n",
        "  allpercentidentities.append(percent_identity)\n",
        "  modified_prompt = list(row['substituted_seq'])\n",
        "  for index in maskedindeces:\n",
        "      modified_prompt[index] = \"_\"\n",
        "  modified_prompt = \"\".join(modified_prompt)\n",
        "  masked_sequence.append(modified_prompt)\n",
        "  protein_prompt = ESMProtein(sequence=modified_prompt)\n",
        "  sequence_generation = model.generate(\n",
        "      protein_prompt,\n",
        "      GenerationConfig(\n",
        "          track=\"sequence\",\n",
        "          num_steps=protein_prompt.sequence.count(\"_\") // 2,\n",
        "          temperature=0.5,\n",
        "      ),\n",
        "  )\n",
        "  generated_sequence = sequence_generation.sequence\n",
        "  generated_sequence_list.append(generated_sequence)\n",
        "  # Ensure sequences are of equal length\n",
        "  if len(generated_sequence) != len(row['sequence']):\n",
        "      print(\"Sequences must be of the same length to calculate Hamming distance.\")\n",
        "      sequence_similarity.append(None)\n",
        "  else:\n",
        "      blosum_score = 0\n",
        "      for gen_residue, target_residue in zip(generated_sequence, row['sequence']):\n",
        "          blosum_val =  matrix[gen_residue][target_residue]\n",
        "          blosum_score += blosum_val\n",
        "      blosum_score = blosum_score / len(generated_sequence)\n",
        "      sequence_similarity.append(blosum_score)\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "shortenedpercentmasks = [allpercentmasks[i] for i in allindexes]\n",
        "df2 = pd.DataFrame({\n",
        "    'Number of Interpro Terms': allnuminterpro,\n",
        "    'Percentage Deleted': shortenedpercentmasks,\n",
        "    'Percent Correct': allpercentidentities,\n",
        "    'Index': allindexes,\n",
        "    'Masked sites': allmasked,\n",
        "    'Sequence Similarity': sequence_similarity,\n",
        "    'Generated Sequences': generated_sequence_list,\n",
        "    'Masked Sequences': masked_sequence\n",
        "})\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df2.to_csv('with_seq_similarity_embedding_output_full.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yI__xoTod5d",
        "outputId": "1edfc5eb-48b9-4bea-b791-1b887d5ca426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 12.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(63, 1536)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 12.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(69, 1536)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 12.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(490, 1536)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(101, 1536)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 12.69it/s]\n"
          ]
        }
      ]
    }
  ]
}